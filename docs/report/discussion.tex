Regarding the question of suitability of NVSHMEM for database usage in general and shuffling in particular we take away the following observations from this work. 
Firstly the performance overhead and behaviour of NVSHMEM-provided communication functions is non trivial to understand. Not only the big configuration space introduced by the two dimensions grid and block size have an impact on the results, but NVIDIA itself states that the underlying interconnect technology can have significant impact on the performance and resulting best practices \cite{NVIDIA2022}. This work is focused on evaluating the case of Infinband communication between nodes and the results apply for this scenario. If additionally other interconnects like NVLINK are used, different approaches might yield better results.
Secondly it has been shown that for the tested configuration the behaviour of the non-blocking interface does not match the specification. The source of this divergence is unclear however this unintended blocking impacts the performance limit of our asynchronous communication approach. Further investigation is needed to determine the concrete cause and possibly correct configuration errors.
Further the NVSHMEM programming model and memory model is primarily intended for use in high performance computing scenarios. The symmetric memory abstraction requires preallocating memory before launching a kernel and dynamic memory management during kernel run time is severely limited. Also the launcher based library initialization is not natural for usage in DBMS where operators are dynamically launched for different queries and table sizes and memory requirements can therefore not be known beforehand. It also impedes elasticity, an important topic in today's cloud database systems. 
Lastly our approach, partly as a consequence of NVSHMEM's limitations, assumes that all tuples for shuffling fit in memory of the GPU (16GB in the tested scenario). This requirement can not be imposed in general cases and is in fact unlikely to hold in practical scenarios considering the sizes database tables can reach. Further work towards more complex dynamic batched shuffling is needed to mitigate this limitation.